WORLD_SIZE: 128
NHOSTS: 32
NGPUS: 128
TPSIZE: 8
PPSIZE: 16
MICRO_BATCH: 1
GRADIENT_ACCUMULATION_STEPS: 8
--------------------------------
GLOBAL_BATCH=8 
GLOBAL_BATCH=128 * 1 * 8 / (8 * 16)
--------------------------------
Job started at: 2023-07-21-231553 on x3106c0s13b0n0
Job running in: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/ALCF
Training GPT-3 with 175B parameters
Writing logs in: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8
LOGFILE: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/logs/kaushikvelusamy-x3106c0s13b0n0-nhosts32-ngpu128-2023-07-21-231553.log
to view output: tail -f $(tail -1 logfiles)
i.e. tail -f /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/logs/kaushikvelusamy-x3106c0s13b0n0-nhosts32-ngpu128-2023-07-21-231553.log
OUTPUT LOG: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/logs/kaushikvelusamy-x3106c0s13b0n0-nhosts32-ngpu128-2023-07-21-231553.log
using: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/venvs/polaris/2023-01-10/bin/python3
using: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/venvs/polaris/2023-01-10/bin/python3
Job started at: 2023-07-21-231553 on x3106c0s13b0n0
Job started at: 2023-07-21-231553 on x3106c0s13b0n0
Job running in: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/ALCF
Training GPT-3 with 175B parameters
Writing logs in: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8
Job running in: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/ALCF
Training GPT-3 with 175B parameters
Writing logs in: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8
LOGFILE: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/logs/kaushikvelusamy-x3106c0s13b0n0-nhosts32-ngpu128-2023-07-21-231553.log
to view output: tail -f $(tail -1 logfiles)
LOGFILE: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/logs/kaushikvelusamy-x3106c0s13b0n0-nhosts32-ngpu128-2023-07-21-231553.log
to view output: tail -f $(tail -1 logfiles)
i.e. tail -f /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/logs/kaushikvelusamy-x3106c0s13b0n0-nhosts32-ngpu128-2023-07-21-231553.log
i.e. tail -f /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/logs/kaushikvelusamy-x3106c0s13b0n0-nhosts32-ngpu128-2023-07-21-231553.log
EXEC=/opt/cray/pe/pals/1.1.7/bin/mpiexec     --envall     --verbose     --hostfile /var/spool/pbs/aux/560707.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov     -n 128     --ppn 4 /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/venvs/polaris/2023-01-10/bin/python3 /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/pretrain_gpt.py     --use-flash-attn         --checkpoint-activations       --seed 20548   --DDP-impl local   --pipeline-model-parallel-size 16   --tensor-model-parallel-size 8   --num-layers 96   --hidden-size 12288   --num-attention-heads 96   --micro-batch-size 1   --global-batch-size 8   --seq-length 2048   --max-position-embeddings 2048   --train-iters 5   --lr-decay-iters 320000   --data-path /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document   --vocab-file /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/dataset/gpt2-vocab.json   --merge-file /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/dataset/gpt2-merges.txt   --data-impl mmap   --split 949,50,1   --distributed-backend nccl   --lr 0.00015   --lr-decay-style cosine   --min-lr 1.0e-5   --weight-decay 1e-2   --clip-grad 1.0   --lr-warmup-fraction .01   --log-interval 1   --save-interval 1000   --eval-interval 1000   --eval-iters 1   --tensorboard-dir /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/tensorboard   --log-timers-to-tensorboard   --tensorboard-log-interval 1 --fp16  --deepspeed-activation-checkpointing  --pipeline-model-parallel-size 16  --zero-stage=1  --deepspeed_config=/lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/ds_config-gpt.json  --deepspeed_mpi  --deepspeed 
EXEC=/opt/cray/pe/pals/1.1.7/bin/mpiexec     --envall     --verbose     --hostfile /var/spool/pbs/aux/560707.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov     -n 128     --ppn 4 /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/venvs/polaris/2023-01-10/bin/python3 /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/pretrain_gpt.py     --use-flash-attn         --checkpoint-activations       --seed 20548   --DDP-impl local   --pipeline-model-parallel-size 16   --tensor-model-parallel-size 8   --num-layers 96   --hidden-size 12288   --num-attention-heads 96   --micro-batch-size 1   --global-batch-size 8   --seq-length 2048   --max-position-embeddings 2048   --train-iters 5   --lr-decay-iters 320000   --data-path /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document   --vocab-file /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/dataset/gpt2-vocab.json   --merge-file /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/dataset/gpt2-merges.txt   --data-impl mmap   --split 949,50,1   --distributed-backend nccl   --lr 0.00015   --lr-decay-style cosine   --min-lr 1.0e-5   --weight-decay 1e-2   --clip-grad 1.0   --lr-warmup-fraction .01   --log-interval 1   --save-interval 1000   --eval-interval 1000   --eval-iters 1   --tensorboard-dir /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/tensorboard   --log-timers-to-tensorboard   --tensorboard-log-interval 1 --fp16  --deepspeed-activation-checkpointing  --pipeline-model-parallel-size 16  --zero-stage=1  --deepspeed_config=/lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/ds_config-gpt.json  --deepspeed_mpi  --deepspeed 
Writing logs to: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/logs/kaushikvelusamy-x3106c0s13b0n0-nhosts32-ngpu128-2023-07-21-231553.log
Writing logs to: /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/logs/kaushikvelusamy-x3106c0s13b0n0-nhosts32-ngpu128-2023-07-21-231553.log
Connected to tcp://x3106c0s13b0n0.hsn.cm.polaris.alcf.anl.gov:7919
Launching application fa525c45-eaad-4b06-8373-581cc640e527
2023-07-21 23:16:16.518931: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:16.519364: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:16.519691: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:16.519699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.196904: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.197091: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.197204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.197330: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.305066: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.305348: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.305350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.305480: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.325839: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.325838: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.325909: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.326035: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.326281: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.326287: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.326401: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.327083: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.460261: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.460538: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.460648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.460649: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.681560: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.681614: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.681617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.681760: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.848936: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.848935: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.848938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:17.848936: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.126480: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.126485: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.126678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.127044: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.167153: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.167159: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.167161: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.167158: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.225850: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.226121: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.226315: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.226323: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.485908: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.485901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.485902: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.485907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.539985: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.539984: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.539987: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.539984: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.663774: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.663913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.664069: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.664065: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.851904: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.851900: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.852080: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:18.852196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.013491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.013489: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.013493: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.013486: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.267341: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.267842: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.268411: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.268411: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.485516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.485722: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.485592: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.485878: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.663575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.663941: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.663942: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.664441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.780705: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.780704: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.780707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.780704: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.875880: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.876046: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.876175: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.876383: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.885970: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.886239: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.886238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.886121: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.994939: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.995299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.995420: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:19.995641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.161637: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.161803: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.161808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.161975: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.548774: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.548867: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.549034: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.549234: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.618674: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.618893: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.619009: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.619291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.741316: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.741318: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.741318: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.741323: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.890055: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.890184: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.890191: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.890344: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.913116: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.913240: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.913402: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:20.913566: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.172632: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.173139: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.173146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.173583: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.270134: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.270132: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.270134: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.270132: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.558615: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.558615: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.558615: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-21 23:16:21.558620: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2023-07-21 23:16:41,522] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,522] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,522] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,523] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,600] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,600] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,600] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,600] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,601] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,605] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,605] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,605] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,605] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,724] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,724] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,724] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,725] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,880] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,905] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,905] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,905] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:41,905] [INFO] [comm.py:570:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=8, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=24, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=52, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=68, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=76, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=100, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=1, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=9, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=12, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=16, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=20, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=25, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=32, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=36, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=40, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=44, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=53, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=56, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=60, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=69, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=72, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=77, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=80, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=84, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=92, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=101, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=104, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=108, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=112, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=116, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=120, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=124, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=2, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=4, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=10, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=13, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=17, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=21, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=26, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=28, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=33, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=37, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=41, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=45, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=48, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=54, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=57, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=61, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=64, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=70, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=73, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=78, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=81, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=85, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=88, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=93, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=96, local_rank=0, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=102, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=105, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=109, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=113, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=117, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=121, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=125, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=3, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=5, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=11, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=14, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=18, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=22, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=27, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=29, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=34, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=38, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=42, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=46, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=49, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=55, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=58, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=62, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=65, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=71, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=74, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=79, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=82, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=86, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=89, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=94, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=97, local_rank=1, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=103, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=106, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=110, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=114, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=118, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=122, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=126, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=6, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=15, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=19, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=23, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=30, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=35, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=39, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=43, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=47, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=50, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=59, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=63, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=66, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=75, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=83, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=87, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=90, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=95, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=98, local_rank=2, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=107, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=111, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=115, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=119, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=123, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=127, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=7, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=31, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=51, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=67, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=91, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
[2023-07-21 23:16:48,235] [INFO] [comm.py:620:mpi_discovery] Discovered MPI settings of world_rank=99, local_rank=3, world_size=128, master_addr=10.140.57.223, master_port=29500
wandb: Currently logged in as: kaushik-v (alcf-test). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.10
wandb: Run data is saved locally in /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/tensorboard/wandb/run-20230721_231654-2cpu87xm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-snow-10
wandb: ⭐️ View project at https://wandb.ai/alcf-test/Megatron-LM
wandb: 🚀 View run at https://wandb.ai/alcf-test/Megatron-LM/runs/2cpu87xm
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
async_io ............... [93m[NO][0m ....... [92m[OKAY][0m
cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
sparse_attn ............ [93m[NO][0m ....... [92m[OKAY][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
utils .................. [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/torch']
torch version .................... 1.13.0a0+git49444c3
deepspeed install path ........... ['/lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/venvs/polaris/2023-01-10/lib/python3.10/site-packages/deepspeed']
deepspeed info ................... 0.9.0, unknown, unknown
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 1.13, cuda 11.8
**** Git info for Megatron: git_hash=839629d git_branch=main ****
using world size: 128, data-parallel-size: 1, tensor-model-parallel size: 8, pipeline-model-parallel size: 16 
using torch.float16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  aml_data_download_path .......................... None
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  bert_binary_head ................................ True
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  checkpoint_activations .......................... True
  checkpoint_in_cpu ............................... False
  checkpoint_num_layers ........................... 1
  clip_grad ....................................... 1.0
  compression_training ............................ False
  consumed_train_samples .......................... 0
  consumed_train_tokens ........................... 0
  consumed_valid_samples .......................... 0
  contigious_checkpointing ........................ False
  cpu_optimizer ................................... False
  cpu_torch_adam .................................. False
  create_moe_param_group .......................... False
  curriculum_learning_legacy ...................... False
  custom_token_counting ........................... False
  data_efficiency_curriculum_learning ............. False
  data_impl ....................................... mmap
  data_parallel_size .............................. 1
  data_path ....................................... ['/lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document']
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_seq_length .............................. None
  deepscale ....................................... False
  deepscale_config ................................ None
  deepspeed ....................................... True
  deepspeed_activation_checkpointing .............. True
  deepspeed_config ................................ /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/ds_config-gpt.json
  deepspeed_mpi ................................... True
  distribute_checkpointed_activations ............. False
  distributed_backend ............................. nccl
  ds_inference .................................... False
  ds_pipeline_enabled ............................. True
  embedding_path .................................. None
  enable_expert_tensor_parallelism ................ False
  encoder_seq_length .............................. 2048
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 1
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  expert_interval ................................. 2
  ffn_hidden_size ................................. 49152
  finetune ........................................ False
  fp16 ............................................ True
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  global_batch_size ............................... 8
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 12288
  hidden_size_teacher ............................. None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_dim ......................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference ....................................... False
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  kd .............................................. False
  kd_alpha_ce ..................................... 1
  kd_beta_ce ...................................... 1
  kd_temp ......................................... 1.0
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  load_teacher .................................... None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 1
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_num_zeros_in_grad ........................... False
  log_optimizer_states_to_tensorboard ............. False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... True
  log_validation_ppl_to_tensorboard ............... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_decay_tokens ................................. None
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  lr_warmup_tokens ................................ None
  make_vocab_size_divisible_by .................... 128
  mask_prob ....................................... 0.15
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 2048
  memory_centric_tiled_linear ..................... False
  merge_file ...................................... /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/dataset/gpt2-merges.txt
  micro_batch_size ................................ 1
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mlp_type ........................................ standard
  mmap_warmup ..................................... False
  moe_eval_capacity_factor ........................ 1.0
  moe_expert_parallel_size ........................ 1
  moe_loss_coeff .................................. 0.1
  moe_min_capacity ................................ 4
  moe_token_dropping .............................. True
  moe_train_capacity_factor ....................... 1.0
  mos ............................................. False
  no_load_lr_state ................................ False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_pipeline_parallel ............................ False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 96
  num_attention_heads_teacher ..................... None
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... [1]
  num_experts_teacher ............................. [1]
  num_layers ...................................... 96
  num_layers_per_virtual_pipeline_stage ........... None
  num_layers_teacher .............................. None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  override_lr_scheduler ........................... False
  params_dtype .................................... torch.float16
  partition_activations ........................... False
  patch_dim ....................................... 16
  pipeline_model_parallel_size .................... 16
  profile_backward ................................ False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  random_ltd ...................................... False
  rank ............................................ 0
  remote_device ................................... none
  reset_attention_mask ............................ False
  reset_iteration ................................. False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  return_data_index ............................... False
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  scattered_embeddings ............................ False
  seed ............................................ 20548
  seq_length ...................................... 2048
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  split_transformers .............................. False
  synchronize_each_layer .......................... False
  tensor_model_parallel_size ...................... 8
  tensorboard_dir ................................. /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/tensorboard
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  tile_factor ..................................... 1
  titles_data_path ................................ None
  tokenizer_type .................................. GPT2BPETokenizer
  topk ............................................ 1
  train_data_exact_num_epochs ..................... None
  train_doc_idx_path .............................. None
  train_idx_path .................................. None
  train_iters ..................................... 5
  train_sample_idx_path ........................... None
  train_samples ................................... None
  train_shuffle_idx_path .......................... None
  train_tokens .................................... None
  use_checkpoint_lr_scheduler ..................... False
  use_contiguous_buffers_in_ddp ................... False
  use_cpu_initialization .......................... None
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_pin_memory .................................. False
  use_tutel ....................................... False
  virtual_pipeline_model_parallel_size ............ None
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/dataset/gpt2-vocab.json
  weight_decay .................................... 0.01
  world_size ...................................... 128
  zero_allgather_bucket_size ...................... 0.0
  zero_contigious_gradients ....................... False
  zero_reduce_bucket_size ......................... 0.0
  zero_reduce_scatter ............................. False
  zero_stage ...................................... 1
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 8
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 943 dummy tokens (new size: 51200)
torch distributed is already initialized, skipping initialization ...
> initializing tensor model parallel with size 8
> initializing pipeline model parallel with size 16
> setting random seeds to 20548 ...
[2023-07-21 23:17:20,168] [INFO] [checkpointing.py:226:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 23266 and data parallel seed: 20548
make: Entering directory '/lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/megatron/data'
> compiling dataset index builder ...
>>> done with dataset index builder. Compilation time: 0.067 seconds
> compiling and loading fused kernels ...
Detected CUDA files, patching ldflags
Emitting ninja build file /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
Building extension module scaled_upper_triang_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module scaled_upper_triang_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
Building extension module scaled_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module scaled_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /lus/grand/projects/datascience/kaushikv/dlio/ml_workloads/gpt-alcf/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
Building extension module fused_mix_prec_layer_norm_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_mix_prec_layer_norm_cuda...
NCCL version 2.14.3+cuda11.8
>>> done with compiling and loading fused kernels. Compilation time: 20.396 seconds
time to initialize megatron (seconds): 20.649
[after megatron is initialized] datetime: 2023-07-21 23:17:40 
building GPT model ...
[2023-07-21 23:17:40,861] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[2023-07-21 23:17:40,862] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2023-07-21 23:17:40,863] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 36.04 GB, percent = 7.2%
SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=0, model=1): 1, ProcessCoord(pipe=0, data=0, model=2): 2, ProcessCoord(pipe=0, data=0, model=3): 3, ProcessCoord(pipe=0, data=0, model=4): 4, ProcessCoord(pipe=0, data=0, model=5): 5, ProcessCoord(pipe=0, data=0, model=6): 6, ProcessCoord(pipe=0, data=0, model=7): 7, ProcessCoord(pipe=1, data=0, model=0): 8, ProcessCoord(pipe=1, data=0, model=1): 9, ProcessCoord(pipe=1, data=0, model=2): 10, ProcessCoord(pipe=1, data=0, model=3): 11, ProcessCoord(pipe=1, data=0, model=4): 12, ProcessCoord(pipe=1, data=0, model=5): 13, ProcessCoord(pipe=1, data=0, model=6): 14, ProcessCoord(pipe=1, data=0, model=7): 15, ProcessCoord(pipe=2, data=0, model=0): 16, ProcessCoord(pipe=2, data=0, model=1): 17, ProcessCoord(pipe=2, data=0, model=2): 18, ProcessCoord(pipe=2, data=0, model=3): 19, ProcessCoord(pipe=2, data=0, model=4): 20, ProcessCoord(pipe=2, data=0, model=5): 21, ProcessCoord(pipe=2, data=0, model=6): 22, ProcessCoord(pipe=2, data=0, model=7): 23, ProcessCoord(pipe=3, data=0, model=0): 24, ProcessCoord(pipe=3, data=0, model=1): 25, ProcessCoord(pipe=3, data=0, model=2): 26, ProcessCoord(pipe=3, data=0, model=3): 27, ProcessCoord(pipe=3, data=0, model=4): 28, ProcessCoord(pipe=3, data=0, model=5): 29, ProcessCoord(pipe=3, data=0, model=6): 30, ProcessCoord(pipe=3, data=0, model=7): 31, ProcessCoord(pipe=4, data=0, model=0): 32, ProcessCoord(pipe=4, data=0, model=1): 33, ProcessCoord(pipe=4, data=0, model=2): 34, ProcessCoord(pipe=4, data=0, model=3): 35, ProcessCoord(pipe=4, data=0, model=4): 36, ProcessCoord(pipe=4, data=0, model=5): 37, ProcessCoord(pipe=4, data=0, model=6): 38, ProcessCoord(pipe=4, data=0, model=7): 39, ProcessCoord(pipe=5, data=0, model=0): 40, ProcessCoord(pipe=5, data=0, model=1): 41, ProcessCoord(pipe=5, data=0, model=2): 42, ProcessCoord(pipe=5, data=0, model=3): 43, ProcessCoord(pipe=5, data=0, model=4): 44, ProcessCoord(pipe=5, data=0, model=5): 45, ProcessCoord(pipe=5, data=0, model=6): 46, ProcessCoord(pipe=5, data=0, model=7): 47, ProcessCoord(pipe=6, data=0, model=0): 48, ProcessCoord(pipe=6, data=0, model=1): 49, ProcessCoord(pipe=6, data=0, model=2): 50, ProcessCoord(pipe=6, data=0, model=3): 51, ProcessCoord(pipe=6, data=0, model=4): 52, ProcessCoord(pipe=6, data=0, model=5): 53, ProcessCoord(pipe=6, data=0, model=6): 54, ProcessCoord(pipe=6, data=0, model=7): 55, ProcessCoord(pipe=7, data=0, model=0): 56, ProcessCoord(pipe=7, data=0, model=1): 57, ProcessCoord(pipe=7, data=0, model=2): 58, ProcessCoord(pipe=7, data=0, model=3): 59, ProcessCoord(pipe=7, data=0, model=4): 60, ProcessCoord(pipe=7, data=0, model=5): 61, ProcessCoord(pipe=7, data=0, model=6): 62, ProcessCoord(pipe=7, data=0, model=7): 63, ProcessCoord(pipe=8, data=0, model=0): 64, ProcessCoord(pipe=8, data=0, model=1): 65, ProcessCoord(pipe=8, data=0, model=2): 66, ProcessCoord(pipe=8, data=0, model=3): 67, ProcessCoord(pipe=8, data=0, model=4): 68, ProcessCoord(pipe=8, data=0, model=5): 69, ProcessCoord(pipe=8, data=0, model=6): 70, ProcessCoord(pipe=8, data=0, model=7): 71, ProcessCoord(pipe=9, data=0, model=0): 72, ProcessCoord(pipe=9, data=0, model=1): 73, ProcessCoord(pipe=9, data=0, model=2): 74, ProcessCoord(pipe=9, data=0, model=3): 75, ProcessCoord(pipe=9, data=0, model=4): 76, ProcessCoord(pipe=9, data=0, model=5): 77, ProcessCoord(pipe=9, data=0, model=6): 78, ProcessCoord(pipe=9, data=0, model=7): 79, ProcessCoord(pipe=10, data=0, model=0): 80, ProcessCoord(pipe=10, data=0, model=1): 81, ProcessCoord(pipe=10, data=0, model=2): 82, ProcessCoord(pipe=10, data=0, model=3): 83, ProcessCoord(pipe=10, data=0, model=4): 84, ProcessCoord(pipe=10, data=0, model=5): 85, ProcessCoord(pipe=10, data=0, model=6): 86, ProcessCoord(pipe=10, data=0, model=7): 87, ProcessCoord(pipe=11, data=0, model=0): 88, ProcessCoord(pipe=11, data=0, model=1): 89, ProcessCoord(pipe=11, data=0, model=2): 90, ProcessCoord(pipe=11, data=0, model=3): 91, ProcessCoord(pipe=11, data=0, model=4): 92, ProcessCoord(pipe=11, data=0, model=5): 93, ProcessCoord(pipe=11, data=0, model=6): 94, ProcessCoord(pipe=11, data=0, model=7): 95, ProcessCoord(pipe=12, data=0, model=0): 96, ProcessCoord(pipe=12, data=0, model=1): 97, ProcessCoord(pipe=12, data=0, model=2): 98, ProcessCoord(pipe=12, data=0, model=3): 99, ProcessCoord(pipe=12, data=0, model=4): 100, ProcessCoord(pipe=12, data=0, model=5): 101, ProcessCoord(pipe=12, data=0, model=6): 102, ProcessCoord(pipe=12, data=0, model=7): 103, ProcessCoord(pipe=13, data=0, model=0): 104, ProcessCoord(pipe=13, data=0, model=1): 105, ProcessCoord(pipe=13, data=0, model=2): 106, ProcessCoord(pipe=13, data=0, model=3): 107, ProcessCoord(pipe=13, data=0, model=4): 108, ProcessCoord(pipe=13, data=0, model=5): 109, ProcessCoord(pipe=13, data=0, model=6): 110, ProcessCoord(pipe=13, data=0, model=7): 111, ProcessCoord(pipe=14, data=0, model=0): 112, ProcessCoord(pipe=14, data=0, model=1): 113, ProcessCoord(pipe=14, data=0, model=2): 114, ProcessCoord(pipe=14, data=0, model=3): 115, ProcessCoord(pipe=14, data=0, model=4): 116, ProcessCoord(pipe=14, data=0, model=5): 117, ProcessCoord(pipe=14, data=0, model=6): 118, ProcessCoord(pipe=14, data=0, model=7): 119, ProcessCoord(pipe=15, data=0, model=0): 120, ProcessCoord(pipe=15, data=0, model=1): 121, ProcessCoord(pipe=15, data=0, model=2): 122, ProcessCoord(pipe=15, data=0, model=3): 123, ProcessCoord(pipe=15, data=0, model=4): 124, ProcessCoord(pipe=15, data=0, model=5): 125, ProcessCoord(pipe=15, data=0, model=6): 126, ProcessCoord(pipe=15, data=0, model=7): 127}
[2023-07-21 23:17:42,517] [INFO] [module.py:358:_partition_layers] Partitioning pipeline stages with method type:transformer
 > number of parameters on (tensor, pipeline) model parallel rank (5, 6): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 6): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 11): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 7): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 9): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 12): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 14): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 2): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 3): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 5): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 12): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 13): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 14): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 2): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 3): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (5, 12): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 2): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 3): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 4): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 2): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 4): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 7): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 8): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (5, 2): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (5, 4): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 7): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 8): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 2): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 8): 1359461376
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (7, 3): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 3): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (5, 3): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 3): 1359461376
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (7, 1): 1359461376
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (3, 5): 1359461376
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (2, 5): 1359461376
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (5, 7): 1359461376
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (2, 1): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 5): 1359461376
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (2, 7): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 8): 1359461376
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (6, 6): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 7): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 9): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 14): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 8): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 14): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 9): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 5): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 14): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 9): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 14): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 12): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 10): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 13): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 12): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 5): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 12): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 5): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 9): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 12): 1359461376
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (3, 12): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 6): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 10): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 13): 1359461376
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (4, 8): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 13): 1359461376
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (5, 10): 1359461376
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (3, 4): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (5, 13): 1359461376
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (6, 13): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 11): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 11): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 11): 1359461376
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (5, 5): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 6): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 4): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 1): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 9): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 1): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 3): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (5, 8): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 2): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 7): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (5, 9): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (5, 14): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 2): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 9): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 10): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 10): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (5, 11): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 13): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 1): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 8): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 10): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 10): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 14): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (4, 1): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 4): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (6, 7): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 10): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 11): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (7, 13): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (5, 1): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (0, 4): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 11): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 4): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 6): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (3, 11): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (1, 6): 1359461376
 > number of parameters on (tensor, pipeline) model parallel rank (2, 6): 1359461376
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
NCCL version 2.14.3+cuda11.8
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Emitting ninja build file /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
 > number of parameters on (tensor, pipeline) model parallel rank (1, 15): 1463294976
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (3, 0): 1463270400
 > number of parameters on (tensor, pipeline) model parallel rank (5, 0): 1463270400
 > number of parameters on (tensor, pipeline) model parallel rank (5, 15): 1463294976
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (3, 15): 1463294976
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 1463270400
 > number of parameters on (tensor, pipeline) model parallel rank (7, 0): 1463270400
> setting tensorboard ...
 > number of parameters on (tensor, pipeline) model parallel rank (7, 15): 1463294976
NCCL version 2.14.3+cuda11.8
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Emitting ninja build file /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 15): 1463294976
 > number of parameters on (tensor, pipeline) model parallel rank (4, 0): 1463270400
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (6, 15): 1463294976
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (2, 15): 1463294976
 > number of parameters on (tensor, pipeline) model parallel rank (6, 0): 1463270400
wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (4, 15): 1463294976
NCCL version 2.14.3+cuda11.8
 > number of parameters on (tensor, pipeline) model parallel rank (2, 0): 1463270400
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Emitting ninja build file /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118/utils/build.ninja...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
stage=0 layers=9
     0: _to_float16
     1: EmbeddingPipe
     2: <lambda>
     3: ParallelTransformerLayerPipe
     4: ParallelTransformerLayerPipe
     5: ParallelTransformerLayerPipe
     6: ParallelTransformerLayerPipe
     7: ParallelTransformerLayerPipe
     8: ParallelTransformerLayerPipe
stage=1 layers=6
     9: ParallelTransformerLayerPipe
    10: ParallelTransformerLayerPipe
    11: ParallelTransformerLayerPipe
    12: ParallelTransformerLayerPipe
    13: ParallelTransformerLayerPipe
    14: ParallelTransformerLayerPipe
stage=2 layers=6
    15: ParallelTransformerLayerPipe
    16: ParallelTransformerLayerPipe
    17: ParallelTransformerLayerPipe
    18: ParallelTransformerLayerPipe
    19: ParallelTransformerLayerPipe
    20: ParallelTransformerLayerPipe
stage=3 layers=6
    21: ParallelTransformerLayerPipe
    22: ParallelTransformerLayerPipe
    23: ParallelTransformerLayerPipe
    24: ParallelTransformerLayerPipe
    25: ParallelTransformerLayerPipe
    26: ParallelTransformerLayerPipe
stage=4 layers=6
    27: ParallelTransformerLayerPipe
    28: ParallelTransformerLayerPipe
    29: ParallelTransformerLayerPipe
    30: ParallelTransformerLayerPipe
    31: ParallelTransformerLayerPipe
    32: ParallelTransformerLayerPipe
stage=5 layers=6
    33: ParallelTransformerLayerPipe
    34: ParallelTransformerLayerPipe
    35: ParallelTransformerLayerPipe
    36: ParallelTransformerLayerPipe
    37: ParallelTransformerLayerPipe
    38: ParallelTransformerLayerPipe
stage=6 layers=6
    39: ParallelTransformerLayerPipe
    40: ParallelTransformerLayerPipe
    41: ParallelTransformerLayerPipe
    42: ParallelTransformerLayerPipe
    43: ParallelTransformerLayerPipe
    44: ParallelTransformerLayerPipe
stage=7 layers=6
    45: ParallelTransformerLayerPipe
    46: ParallelTransformerLayerPipe
    47: ParallelTransformerLayerPipe
    48: ParallelTransformerLayerPipe
    49: ParallelTransformerLayerPipe
    50: ParallelTransformerLayerPipe
stage=8 layers=6
    51: ParallelTransformerLayerPipe
    52: ParallelTransformerLayerPipe
    53: ParallelTransformerLayerPipe
    54: ParallelTransformerLayerPipe
    55: ParallelTransformerLayerPipe
    56: ParallelTransformerLayerPipe
stage=9 layers=6
    57: ParallelTransformerLayerPipe
    58: ParallelTransformerLayerPipe
    59: ParallelTransformerLayerPipe
    60: ParallelTransformerLayerPipe
    61: ParallelTransformerLayerPipe
    62: ParallelTransformerLayerPipe
stage=10 layers=6
    63: ParallelTransformerLayerPipe
    64: ParallelTransformerLayerPipe
    65: ParallelTransformerLayerPipe
    66: ParallelTransformerLayerPipe
    67: ParallelTransformerLayerPipe
    68: ParallelTransformerLayerPipe
stage=11 layers=6
    69: ParallelTransformerLayerPipe
    70: ParallelTransformerLayerPipe
    71: ParallelTransformerLayerPipe
    72: ParallelTransformerLayerPipe
    73: ParallelTransformerLayerPipe
    74: ParallelTransformerLayerPipe
stage=12 layers=6
    75: ParallelTransformerLayerPipe
    76: ParallelTransformerLayerPipe
    77: ParallelTransformerLayerPipe
    78: ParallelTransformerLayerPipe
    79: ParallelTransformerLayerPipe
    80: ParallelTransformerLayerPipe
stage=13 layers=6
    81: ParallelTransformerLayerPipe
    82: ParallelTransformerLayerPipe
    83: ParallelTransformerLayerPipe
    84: ParallelTransformerLayerPipe
    85: ParallelTransformerLayerPipe
    86: ParallelTransformerLayerPipe
stage=14 layers=6
    87: ParallelTransformerLayerPipe
    88: ParallelTransformerLayerPipe
    89: ParallelTransformerLayerPipe
    90: ParallelTransformerLayerPipe
    91: ParallelTransformerLayerPipe
    92: ParallelTransformerLayerPipe
stage=15 layers=10
    93: ParallelTransformerLayerPipe
    94: ParallelTransformerLayerPipe
    95: ParallelTransformerLayerPipe
    96: ParallelTransformerLayerPipe
    97: ParallelTransformerLayerPipe
    98: ParallelTransformerLayerPipe
    99: <lambda>
    100: MixedFusedLayerNorm
    101: EmbeddingPipe
    102: float16_to_fp32
  loss: CrossEntropy
[2023-07-21 23:17:44,705] [INFO] [utils.py:785:see_memory_usage] After Building Model
[2023-07-21 23:17:44,707] [INFO] [utils.py:786:see_memory_usage] MA 2.78 GB         Max_MA 2.8 GB         CA 2.8 GB         Max_CA 3 GB 
[2023-07-21 23:17:44,708] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 41.68 GB, percent = 8.3%
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 1463270400
> learning rate decay style: cosine
DeepSpeed is enabled.
[2023-07-21 23:17:44,713] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.0, git-hash=unknown, git-branch=unknown
[2023-07-21 23:17:44,932] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: True
[2023-07-21 23:17:44,934] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-07-21 23:17:44,935] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-07-21 23:17:44,936] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-07-21 23:17:44,936] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2023-07-21 23:17:44,937] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
[2023-07-21 23:17:44,937] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000
[2023-07-21 23:17:44,938] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500000000
[2023-07-21 23:17:44,938] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[2023-07-21 23:17:44,938] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Emitting ninja build file /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.16943645477294922 seconds
Rank: 0 partition count [1, 1] and sizes[(1462763520, False), (506880, False)] 
[2023-07-21 23:17:48,415] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-07-21 23:17:48,416] [INFO] [utils.py:786:see_memory_usage] MA 8.18 GB         Max_MA 8.18 GB         CA 8.19 GB         Max_CA 8 GB 
[2023-07-21 23:17:48,416] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 36.76 GB, percent = 7.3%
[2023-07-21 23:17:48,573] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-07-21 23:17:48,574] [INFO] [utils.py:786:see_memory_usage] MA 19.08 GB         Max_MA 35.43 GB         CA 35.44 GB         Max_CA 35 GB 
[2023-07-21 23:17:48,574] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 36.78 GB, percent = 7.3%
[2023-07-21 23:17:48,574] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-07-21 23:17:48,696] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-07-21 23:17:48,697] [INFO] [utils.py:786:see_memory_usage] MA 19.08 GB         Max_MA 19.08 GB         CA 35.44 GB         Max_CA 35 GB 
[2023-07-21 23:17:48,697] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 36.78 GB, percent = 7.3%
[2023-07-21 23:17:48,699] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-07-21 23:17:48,699] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-07-21 23:17:48,700] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x147010167fd0>
[2023-07-21 23:17:48,700] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]
[2023-07-21 23:17:48,701] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-07-21 23:17:48,701] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-07-21 23:17:48,702] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-07-21 23:17:48,702] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-07-21 23:17:48,702] [INFO] [config.py:957:print]   amp_params ................... False
[2023-07-21 23:17:48,703] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-07-21 23:17:48,703] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-07-21 23:17:48,703] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-07-21 23:17:48,704] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-07-21 23:17:48,704] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-07-21 23:17:48,704] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x147010167e50>
[2023-07-21 23:17:48,704] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-07-21 23:17:48,705] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-07-21 23:17:48,705] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-07-21 23:17:48,705] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-07-21 23:17:48,706] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-07-21 23:17:48,706] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-07-21 23:17:48,706] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-07-21 23:17:48,707] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-07-21 23:17:48,707] [INFO] [config.py:957:print]   dump_state ................... False
[2023-07-21 23:17:48,707] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}
[2023-07-21 23:17:48,707] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-07-21 23:17:48,708] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-07-21 23:17:48,708] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-07-21 23:17:48,708] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-07-21 23:17:48,709] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-07-21 23:17:48,709] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-07-21 23:17:48,709] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-07-21 23:17:48,709] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-07-21 23:17:48,710] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-07-21 23:17:48,710] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": true, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 3, 
    "detailed": true, 
    "output_file": null
}
[2023-07-21 23:17:48,710] [INFO] [config.py:957:print]   fp16_auto_cast ............... False
[2023-07-21 23:17:48,711] [INFO] [config.py:957:print]   fp16_enabled ................. True
[2023-07-21 23:17:48,711] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-07-21 23:17:48,711] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-07-21 23:17:48,711] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-07-21 23:17:48,712] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 8
[2023-07-21 23:17:48,712] [INFO] [config.py:957:print]   gradient_clipping ............ 0.0
[2023-07-21 23:17:48,712] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-07-21 23:17:48,713] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-07-21 23:17:48,713] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 4096
[2023-07-21 23:17:48,713] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-07-21 23:17:48,713] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-07-21 23:17:48,714] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-07-21 23:17:48,714] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=True, group=None, team=None, project='megatron-LM') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=True
[2023-07-21 23:17:48,714] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-07-21 23:17:48,715] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-07-21 23:17:48,715] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-07-21 23:17:48,715] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-07-21 23:17:48,716] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-07-21 23:17:48,716] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-07-21 23:17:48,716] [INFO] [config.py:957:print]   pld_params ................... False
[2023-07-21 23:17:48,716] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-07-21 23:17:48,717] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-07-21 23:17:48,717] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-07-21 23:17:48,717] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-07-21 23:17:48,718] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-07-21 23:17:48,718] [INFO] [config.py:957:print]   steps_per_print .............. 1
[2023-07-21 23:17:48,718] [INFO] [config.py:957:print]   train_batch_size ............. 8
[2023-07-21 23:17:48,718] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[2023-07-21 23:17:48,718] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-07-21 23:17:48,719] [INFO] [config.py:957:print]   wall_clock_breakdown ......... True
[2023-07-21 23:17:48,719] [INFO] [config.py:957:print]   world_size ................... 1
[2023-07-21 23:17:48,719] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-07-21 23:17:48,719] [INFO] [config.py:957:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=PosixPath('/raid/scratch'), buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=True) offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-07-21 23:17:48,720] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-07-21 23:17:48,720] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-07-21 23:17:48,720] [INFO] [config.py:957:print]   zero_optimization_stage ...... 1
[2023-07-21 23:17:48,720] [INFO] [config.py:943:print_user_config]   json = {
    "train_batch_size": 8, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 8, 
    "steps_per_print": 1, 
    "wall_clock_breakdown": true, 
    "zero_optimization": {
        "stage": 1, 
        "allgather_partitions": true, 
        "reduce_scatter": true, 
        "allgather_bucket_size": 5.000000e+08, 
        "overlap_comm": true, 
        "contiguous_gradients": true, 
        "offload_param": {
            "device": "cpu", 
            "nvme_path": "/raid/scratch", 
            "pin_memory": true
        }
    }, 
    "fp16": {
        "enabled": true, 
        "initial_scale_power": 12
    }, 
    "flops_profiler": {
        "enabled": true, 
        "profile_step": 1, 
        "module_depth": -1, 
        "top_modules": 3, 
        "detailed": true, 
        "output_file": null
    }, 
    "comms_logger": {
        "enabled": true, 
        "verbose": false, 
        "prof_all": false, 
        "debug": false
    }, 
    "wandb": {
        "enabled": true, 
        "project": "megatron-LM"
    }
}
Using /home/kaushikvelusamy/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0018422603607177734 seconds
[2023-07-21 23:17:48,723] [INFO] [engine.py:81:__init__] CONFIG: micro_batches=8 micro_batch_size=1
Time to load utils op: 0.10318922996520996 seconds
Rank: 1 partition count [1, 1] and sizes[(1462763520, False), (506880, False)] 
Time to load utils op: 0.001199483871459961 seconds
[2023-07-21 23:17:56,974] [INFO] [engine.py:136:__init__] RANK=1 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=1463270400 (1463.270M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10494446754455566 seconds
Rank: 2 partition count [1, 1] and sizes[(1462763520, False), (506880, False)] 
Time to load utils op: 0.0010504722595214844 seconds
[2023-07-21 23:17:56,974] [INFO] [engine.py:136:__init__] RANK=2 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=1463270400 (1463.270M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.15428972244262695 seconds
Rank: 3 partition count [1, 1] and sizes[(1462763520, False), (506880, False)] 
Time to load utils op: 0.0012526512145996094 seconds
[2023-07-21 23:17:56,974] [INFO] [engine.py:136:__init__] RANK=3 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=1463270400 (1463.270M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
[2023-07-21 23:17:56,976] [INFO] [engine.py:136:__init__] RANK=0 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=1463270400 (1463.270M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.21173906326293945 seconds
Rank: 65 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0010685920715332031 seconds
[2023-07-21 23:17:56,976] [INFO] [engine.py:136:__init__] RANK=65 STAGE=8 LAYERS=6 [51, 57) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.21213746070861816 seconds
Rank: 66 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001348733901977539 seconds
[2023-07-21 23:17:56,976] [INFO] [engine.py:136:__init__] RANK=66 STAGE=8 LAYERS=6 [51, 57) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.21207547187805176 seconds
Rank: 67 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014312267303466797 seconds
[2023-07-21 23:17:56,976] [INFO] [engine.py:136:__init__] RANK=67 STAGE=8 LAYERS=6 [51, 57) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.21109986305236816 seconds
Rank: 64 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0012278556823730469 seconds
[2023-07-21 23:17:56,976] [INFO] [engine.py:136:__init__] RANK=64 STAGE=8 LAYERS=6 [51, 57) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11094927787780762 seconds
Rank: 32 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014538764953613281 seconds
[2023-07-21 23:17:56,977] [INFO] [engine.py:136:__init__] RANK=32 STAGE=4 LAYERS=6 [27, 33) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11170363426208496 seconds
Rank: 33 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001168966293334961 seconds
[2023-07-21 23:17:56,977] [INFO] [engine.py:136:__init__] RANK=33 STAGE=4 LAYERS=6 [27, 33) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.1105186939239502 seconds
Rank: 34 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014164447784423828 seconds
[2023-07-21 23:17:56,977] [INFO] [engine.py:136:__init__] RANK=34 STAGE=4 LAYERS=6 [27, 33) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.12085390090942383 seconds
Rank: 49 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016009807586669922 seconds
[2023-07-21 23:17:56,977] [INFO] [engine.py:136:__init__] RANK=49 STAGE=6 LAYERS=6 [39, 45) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10882425308227539 seconds
Rank: 56 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001379251480102539 seconds
[2023-07-21 23:17:56,978] [INFO] [engine.py:136:__init__] RANK=56 STAGE=7 LAYERS=6 [45, 51) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20462632179260254 seconds
Rank: 35 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015342235565185547 seconds
[2023-07-21 23:17:56,977] [INFO] [engine.py:136:__init__] RANK=35 STAGE=4 LAYERS=6 [27, 33) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.12075448036193848 seconds
Rank: 50 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0017633438110351562 seconds
[2023-07-21 23:17:56,977] [INFO] [engine.py:136:__init__] RANK=50 STAGE=6 LAYERS=6 [39, 45) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20444536209106445 seconds
Rank: 57 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001710653305053711 seconds
[2023-07-21 23:17:56,978] [INFO] [engine.py:136:__init__] RANK=57 STAGE=7 LAYERS=6 [45, 51) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.12125825881958008 seconds
Rank: 51 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0018992424011230469 seconds
[2023-07-21 23:17:56,977] [INFO] [engine.py:136:__init__] RANK=51 STAGE=6 LAYERS=6 [39, 45) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20289325714111328 seconds
Rank: 52 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013425350189208984 seconds
[2023-07-21 23:17:56,978] [INFO] [engine.py:136:__init__] RANK=52 STAGE=6 LAYERS=6 [39, 45) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10901165008544922 seconds
Rank: 58 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015110969543457031 seconds
[2023-07-21 23:17:56,978] [INFO] [engine.py:136:__init__] RANK=58 STAGE=7 LAYERS=6 [45, 51) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20517802238464355 seconds
Rank: 48 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013842582702636719 seconds
[2023-07-21 23:17:56,977] [INFO] [engine.py:136:__init__] RANK=48 STAGE=6 LAYERS=6 [39, 45) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20483160018920898 seconds
Rank: 53 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015163421630859375 seconds
[2023-07-21 23:17:56,978] [INFO] [engine.py:136:__init__] RANK=53 STAGE=6 LAYERS=6 [39, 45) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10867118835449219 seconds
Rank: 59 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014011859893798828 seconds
[2023-07-21 23:17:56,978] [INFO] [engine.py:136:__init__] RANK=59 STAGE=7 LAYERS=6 [45, 51) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11018991470336914 seconds
Rank: 54 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015978813171386719 seconds
[2023-07-21 23:17:56,978] [INFO] [engine.py:136:__init__] RANK=54 STAGE=6 LAYERS=6 [39, 45) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20270109176635742 seconds
Rank: 55 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015277862548828125 seconds
[2023-07-21 23:17:56,978] [INFO] [engine.py:136:__init__] RANK=55 STAGE=6 LAYERS=6 [39, 45) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20404505729675293 seconds
Rank: 17 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014810562133789062 seconds
[2023-07-21 23:17:56,980] [INFO] [engine.py:136:__init__] RANK=17 STAGE=2 LAYERS=6 [15, 21) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10904526710510254 seconds
Rank: 18 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001093149185180664 seconds
[2023-07-21 23:17:56,980] [INFO] [engine.py:136:__init__] RANK=18 STAGE=2 LAYERS=6 [15, 21) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20388150215148926 seconds
Rank: 19 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0012121200561523438 seconds
[2023-07-21 23:17:56,980] [INFO] [engine.py:136:__init__] RANK=19 STAGE=2 LAYERS=6 [15, 21) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20287156105041504 seconds
Rank: 16 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014619827270507812 seconds
[2023-07-21 23:17:56,980] [INFO] [engine.py:136:__init__] RANK=16 STAGE=2 LAYERS=6 [15, 21) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.2025146484375 seconds
Rank: 97 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016562938690185547 seconds
[2023-07-21 23:17:56,989] [INFO] [engine.py:136:__init__] RANK=97 STAGE=12 LAYERS=6 [75, 81) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20288968086242676 seconds
Rank: 98 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015361309051513672 seconds
[2023-07-21 23:17:56,989] [INFO] [engine.py:136:__init__] RANK=98 STAGE=12 LAYERS=6 [75, 81) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20277714729309082 seconds
Rank: 99 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014851093292236328 seconds
[2023-07-21 23:17:56,989] [INFO] [engine.py:136:__init__] RANK=99 STAGE=12 LAYERS=6 [75, 81) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.21345186233520508 seconds
Rank: 96 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014808177947998047 seconds
[2023-07-21 23:17:56,989] [INFO] [engine.py:136:__init__] RANK=96 STAGE=12 LAYERS=6 [75, 81) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10264372825622559 seconds
Rank: 81 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0017762184143066406 seconds
[2023-07-21 23:17:56,989] [INFO] [engine.py:136:__init__] RANK=81 STAGE=10 LAYERS=6 [63, 69) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11339330673217773 seconds
Rank: 82 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014078617095947266 seconds
[2023-07-21 23:17:56,989] [INFO] [engine.py:136:__init__] RANK=82 STAGE=10 LAYERS=6 [63, 69) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.1044321060180664 seconds
Rank: 83 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016760826110839844 seconds
[2023-07-21 23:17:56,989] [INFO] [engine.py:136:__init__] RANK=83 STAGE=10 LAYERS=6 [63, 69) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10423660278320312 seconds
Rank: 80 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014100074768066406 seconds
[2023-07-21 23:17:56,989] [INFO] [engine.py:136:__init__] RANK=80 STAGE=10 LAYERS=6 [63, 69) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.15442109107971191 seconds
Rank: 88 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0010373592376708984 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=88 STAGE=11 LAYERS=6 [69, 75) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10258078575134277 seconds
Rank: 89 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014100074768066406 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=89 STAGE=11 LAYERS=6 [69, 75) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.21270990371704102 seconds
Rank: 84 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014717578887939453 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=84 STAGE=10 LAYERS=6 [63, 69) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10241007804870605 seconds
Rank: 90 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0012133121490478516 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=90 STAGE=11 LAYERS=6 [69, 75) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20290088653564453 seconds
Rank: 85 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016634464263916016 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=85 STAGE=10 LAYERS=6 [63, 69) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10639572143554688 seconds
Rank: 91 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013000965118408203 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=91 STAGE=11 LAYERS=6 [69, 75) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20275235176086426 seconds
Rank: 86 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0017087459564208984 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=86 STAGE=10 LAYERS=6 [63, 69) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11149239540100098 seconds
Rank: 92 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0011827945709228516 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=92 STAGE=11 LAYERS=6 [69, 75) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.2030487060546875 seconds
Rank: 87 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015211105346679688 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=87 STAGE=10 LAYERS=6 [63, 69) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11149477958679199 seconds
Rank: 93 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014617443084716797 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=93 STAGE=11 LAYERS=6 [69, 75) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11148953437805176 seconds
Rank: 94 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013976097106933594 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=94 STAGE=11 LAYERS=6 [69, 75) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11149215698242188 seconds
Rank: 95 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013744831085205078 seconds
[2023-07-21 23:17:56,990] [INFO] [engine.py:136:__init__] RANK=95 STAGE=11 LAYERS=6 [69, 75) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11302018165588379 seconds
Rank: 40 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001542806625366211 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=40 STAGE=5 LAYERS=6 [33, 39) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11302375793457031 seconds
Rank: 41 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016145706176757812 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=41 STAGE=5 LAYERS=6 [33, 39) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11302375793457031 seconds
Rank: 42 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015034675598144531 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=42 STAGE=5 LAYERS=6 [33, 39) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.1130361557006836 seconds
Rank: 43 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015413761138916016 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=43 STAGE=5 LAYERS=6 [33, 39) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20498061180114746 seconds
Rank: 72 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014433860778808594 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=72 STAGE=9 LAYERS=6 [57, 63) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11074256896972656 seconds
Rank: 73 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.00159454345703125 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=73 STAGE=9 LAYERS=6 [57, 63) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11039352416992188 seconds
Rank: 76 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001668691635131836 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=76 STAGE=9 LAYERS=6 [57, 63) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20299243927001953 seconds
Rank: 74 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013093948364257812 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=74 STAGE=9 LAYERS=6 [57, 63) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11136436462402344 seconds
Rank: 77 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015518665313720703 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=77 STAGE=9 LAYERS=6 [57, 63) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20311856269836426 seconds
Rank: 75 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016918182373046875 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=75 STAGE=9 LAYERS=6 [57, 63) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11142635345458984 seconds
Rank: 78 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016188621520996094 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=78 STAGE=9 LAYERS=6 [57, 63) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20496559143066406 seconds
Rank: 79 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.00162506103515625 seconds
[2023-07-21 23:17:56,991] [INFO] [engine.py:136:__init__] RANK=79 STAGE=9 LAYERS=6 [57, 63) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10937118530273438 seconds
Rank: 9 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001081228256225586 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=9 STAGE=1 LAYERS=6 [9, 15) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20533180236816406 seconds
Rank: 25 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013849735260009766 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=25 STAGE=3 LAYERS=6 [21, 27) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20429372787475586 seconds
Rank: 10 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014004707336425781 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=10 STAGE=1 LAYERS=6 [9, 15) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10903549194335938 seconds
Rank: 26 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015518665313720703 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=26 STAGE=3 LAYERS=6 [21, 27) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.1095271110534668 seconds
Rank: 11 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001386404037475586 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=11 STAGE=1 LAYERS=6 [9, 15) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10952544212341309 seconds
Rank: 27 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.00153350830078125 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=27 STAGE=3 LAYERS=6 [21, 27) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20464372634887695 seconds
Rank: 4 partition count [1, 1] and sizes[(1462763520, False), (506880, False)] 
Time to load utils op: 0.0015795230865478516 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=4 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=1463270400 (1463.270M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20450162887573242 seconds
Rank: 8 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001346588134765625 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=8 STAGE=1 LAYERS=6 [9, 15) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.2030959129333496 seconds
Rank: 24 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0018491744995117188 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=24 STAGE=3 LAYERS=6 [21, 27) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11234188079833984 seconds
Rank: 5 partition count [1, 1] and sizes[(1462763520, False), (506880, False)] 
Time to load utils op: 0.0013167858123779297 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=5 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=1463270400 (1463.270M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10408997535705566 seconds
Rank: 6 partition count [1, 1] and sizes[(1462763520, False), (506880, False)] 
Time to load utils op: 0.0014986991882324219 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=6 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=1463270400 (1463.270M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.1117391586303711 seconds
Rank: 28 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001481771469116211 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=28 STAGE=3 LAYERS=6 [21, 27) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10283803939819336 seconds
Rank: 7 partition count [1, 1] and sizes[(1462763520, False), (506880, False)] 
Time to load utils op: 0.0015952587127685547 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=7 STAGE=0 LAYERS=9 [0, 9) STAGE_PARAMS=1463270400 (1463.270M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10673022270202637 seconds
Rank: 12 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0012979507446289062 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=12 STAGE=1 LAYERS=6 [9, 15) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11205410957336426 seconds
Rank: 29 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016868114471435547 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=29 STAGE=3 LAYERS=6 [21, 27) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20487046241760254 seconds
Rank: 60 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015664100646972656 seconds
[2023-07-21 23:17:56,993] [INFO] [engine.py:136:__init__] RANK=60 STAGE=7 LAYERS=6 [45, 51) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.12358450889587402 seconds
Rank: 13 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013899803161621094 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=13 STAGE=1 LAYERS=6 [9, 15) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11327099800109863 seconds
Rank: 30 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0017769336700439453 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=30 STAGE=3 LAYERS=6 [21, 27) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20295119285583496 seconds
Rank: 61 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015993118286132812 seconds
[2023-07-21 23:17:56,993] [INFO] [engine.py:136:__init__] RANK=61 STAGE=7 LAYERS=6 [45, 51) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11864924430847168 seconds
Rank: 14 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015375614166259766 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=14 STAGE=1 LAYERS=6 [9, 15) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11219358444213867 seconds
Rank: 31 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016841888427734375 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=31 STAGE=3 LAYERS=6 [21, 27) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11025881767272949 seconds
Rank: 62 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013556480407714844 seconds
[2023-07-21 23:17:56,993] [INFO] [engine.py:136:__init__] RANK=62 STAGE=7 LAYERS=6 [45, 51) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20445895195007324 seconds
Rank: 15 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0017962455749511719 seconds
[2023-07-21 23:17:56,992] [INFO] [engine.py:136:__init__] RANK=15 STAGE=1 LAYERS=6 [9, 15) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11446404457092285 seconds
Rank: 36 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014879703521728516 seconds
[2023-07-21 23:17:56,993] [INFO] [engine.py:136:__init__] RANK=36 STAGE=4 LAYERS=6 [27, 33) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10657620429992676 seconds
Rank: 63 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014772415161132812 seconds
[2023-07-21 23:17:56,993] [INFO] [engine.py:136:__init__] RANK=63 STAGE=7 LAYERS=6 [45, 51) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20500826835632324 seconds
Rank: 37 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001600503921508789 seconds
[2023-07-21 23:17:56,993] [INFO] [engine.py:136:__init__] RANK=37 STAGE=4 LAYERS=6 [27, 33) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11458134651184082 seconds
Rank: 38 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016620159149169922 seconds
[2023-07-21 23:17:56,993] [INFO] [engine.py:136:__init__] RANK=38 STAGE=4 LAYERS=6 [27, 33) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20286774635314941 seconds
Rank: 39 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015993118286132812 seconds
[2023-07-21 23:17:56,993] [INFO] [engine.py:136:__init__] RANK=39 STAGE=4 LAYERS=6 [27, 33) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.12625837326049805 seconds
Rank: 20 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013580322265625 seconds
[2023-07-21 23:17:56,994] [INFO] [engine.py:136:__init__] RANK=20 STAGE=2 LAYERS=6 [15, 21) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.12625718116760254 seconds
Rank: 21 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001711130142211914 seconds
[2023-07-21 23:17:56,994] [INFO] [engine.py:136:__init__] RANK=21 STAGE=2 LAYERS=6 [15, 21) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.12626051902770996 seconds
Rank: 22 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015463829040527344 seconds
[2023-07-21 23:17:56,994] [INFO] [engine.py:136:__init__] RANK=22 STAGE=2 LAYERS=6 [15, 21) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.12625598907470703 seconds
Rank: 23 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014269351959228516 seconds
[2023-07-21 23:17:56,994] [INFO] [engine.py:136:__init__] RANK=23 STAGE=2 LAYERS=6 [15, 21) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11281895637512207 seconds
Rank: 112 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0009739398956298828 seconds
[2023-07-21 23:17:57,000] [INFO] [engine.py:136:__init__] RANK=112 STAGE=14 LAYERS=6 [87, 93) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11281418800354004 seconds
Rank: 113 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0012922286987304688 seconds
[2023-07-21 23:17:57,000] [INFO] [engine.py:136:__init__] RANK=113 STAGE=14 LAYERS=6 [87, 93) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11281847953796387 seconds
Rank: 114 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0011467933654785156 seconds
[2023-07-21 23:17:57,000] [INFO] [engine.py:136:__init__] RANK=114 STAGE=14 LAYERS=6 [87, 93) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.1128072738647461 seconds
Rank: 115 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001071929931640625 seconds
[2023-07-21 23:17:57,000] [INFO] [engine.py:136:__init__] RANK=115 STAGE=14 LAYERS=6 [87, 93) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.17696690559387207 seconds
Rank: 120 partition count [1, 1] and sizes[(1462763520, False), (531456, False)] 
Time to load utils op: 0.0019259452819824219 seconds
[2023-07-21 23:17:57,000] [INFO] [engine.py:136:__init__] RANK=120 STAGE=15 LAYERS=10 [93, 103) STAGE_PARAMS=1463294976 (1463.295M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11264467239379883 seconds
Rank: 121 partition count [1, 1] and sizes[(1462763520, False), (531456, False)] 
Time to load utils op: 0.0014138221740722656 seconds
[2023-07-21 23:17:57,000] [INFO] [engine.py:136:__init__] RANK=121 STAGE=15 LAYERS=10 [93, 103) STAGE_PARAMS=1463294976 (1463.295M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10360598564147949 seconds
Rank: 122 partition count [1, 1] and sizes[(1462763520, False), (531456, False)] 
Time to load utils op: 0.0014569759368896484 seconds
[2023-07-21 23:17:57,000] [INFO] [engine.py:136:__init__] RANK=122 STAGE=15 LAYERS=10 [93, 103) STAGE_PARAMS=1463294976 (1463.295M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10302019119262695 seconds
Rank: 123 partition count [1, 1] and sizes[(1462763520, False), (531456, False)] 
Time to load utils op: 0.0014729499816894531 seconds
[2023-07-21 23:17:57,000] [INFO] [engine.py:136:__init__] RANK=123 STAGE=15 LAYERS=10 [93, 103) STAGE_PARAMS=1463294976 (1463.295M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20456743240356445 seconds
Rank: 116 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013020038604736328 seconds
[2023-07-21 23:17:57,001] [INFO] [engine.py:136:__init__] RANK=116 STAGE=14 LAYERS=6 [87, 93) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11008596420288086 seconds
Rank: 117 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0012865066528320312 seconds
[2023-07-21 23:17:57,001] [INFO] [engine.py:136:__init__] RANK=117 STAGE=14 LAYERS=6 [87, 93) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11000490188598633 seconds
Rank: 118 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013766288757324219 seconds
[2023-07-21 23:17:57,001] [INFO] [engine.py:136:__init__] RANK=118 STAGE=14 LAYERS=6 [87, 93) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11060571670532227 seconds
Rank: 119 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.00104522705078125 seconds
[2023-07-21 23:17:57,001] [INFO] [engine.py:136:__init__] RANK=119 STAGE=14 LAYERS=6 [87, 93) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.2029414176940918 seconds
Rank: 44 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0017189979553222656 seconds
[2023-07-21 23:17:57,002] [INFO] [engine.py:136:__init__] RANK=44 STAGE=5 LAYERS=6 [33, 39) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11066842079162598 seconds
Rank: 45 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001428842544555664 seconds
[2023-07-21 23:17:57,002] [INFO] [engine.py:136:__init__] RANK=45 STAGE=5 LAYERS=6 [33, 39) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11087751388549805 seconds
Rank: 46 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0017328262329101562 seconds
[2023-07-21 23:17:57,002] [INFO] [engine.py:136:__init__] RANK=46 STAGE=5 LAYERS=6 [33, 39) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20463800430297852 seconds
Rank: 47 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016367435455322266 seconds
[2023-07-21 23:17:57,002] [INFO] [engine.py:136:__init__] RANK=47 STAGE=5 LAYERS=6 [33, 39) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10454416275024414 seconds
Rank: 124 partition count [1, 1] and sizes[(1462763520, False), (531456, False)] 
Time to load utils op: 0.0012230873107910156 seconds
[2023-07-21 23:17:57,004] [INFO] [engine.py:136:__init__] RANK=124 STAGE=15 LAYERS=10 [93, 103) STAGE_PARAMS=1463294976 (1463.295M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.1123359203338623 seconds
Rank: 125 partition count [1, 1] and sizes[(1462763520, False), (531456, False)] 
Time to load utils op: 0.0016345977783203125 seconds
[2023-07-21 23:17:57,004] [INFO] [engine.py:136:__init__] RANK=125 STAGE=15 LAYERS=10 [93, 103) STAGE_PARAMS=1463294976 (1463.295M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20476889610290527 seconds
Rank: 68 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016300678253173828 seconds
[2023-07-21 23:17:57,004] [INFO] [engine.py:136:__init__] RANK=68 STAGE=8 LAYERS=6 [51, 57) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10412192344665527 seconds
Rank: 126 partition count [1, 1] and sizes[(1462763520, False), (531456, False)] 
Time to load utils op: 0.001142263412475586 seconds
[2023-07-21 23:17:57,004] [INFO] [engine.py:136:__init__] RANK=126 STAGE=15 LAYERS=10 [93, 103) STAGE_PARAMS=1463294976 (1463.295M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10952901840209961 seconds
Rank: 69 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0012507438659667969 seconds
[2023-07-21 23:17:57,004] [INFO] [engine.py:136:__init__] RANK=69 STAGE=8 LAYERS=6 [51, 57) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.10297060012817383 seconds
Rank: 127 partition count [1, 1] and sizes[(1462763520, False), (531456, False)] 
Time to load utils op: 0.0015044212341308594 seconds
[2023-07-21 23:17:57,004] [INFO] [engine.py:136:__init__] RANK=127 STAGE=15 LAYERS=10 [93, 103) STAGE_PARAMS=1463294976 (1463.295M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.1094367504119873 seconds
Rank: 70 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014486312866210938 seconds
[2023-07-21 23:17:57,004] [INFO] [engine.py:136:__init__] RANK=70 STAGE=8 LAYERS=6 [51, 57) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11017751693725586 seconds
Rank: 71 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016429424285888672 seconds
[2023-07-21 23:17:57,004] [INFO] [engine.py:136:__init__] RANK=71 STAGE=8 LAYERS=6 [51, 57) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11332225799560547 seconds
Rank: 104 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0016057491302490234 seconds
[2023-07-21 23:17:57,011] [INFO] [engine.py:136:__init__] RANK=104 STAGE=13 LAYERS=6 [81, 87) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20473814010620117 seconds
Rank: 105 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0012731552124023438 seconds
[2023-07-21 23:17:57,011] [INFO] [engine.py:136:__init__] RANK=105 STAGE=13 LAYERS=6 [81, 87) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11367607116699219 seconds
Rank: 106 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013418197631835938 seconds
[2023-07-21 23:17:57,011] [INFO] [engine.py:136:__init__] RANK=106 STAGE=13 LAYERS=6 [81, 87) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.1129920482635498 seconds
Rank: 107 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015292167663574219 seconds
[2023-07-21 23:17:57,011] [INFO] [engine.py:136:__init__] RANK=107 STAGE=13 LAYERS=6 [81, 87) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11422467231750488 seconds
Rank: 100 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014743804931640625 seconds
[2023-07-21 23:17:57,012] [INFO] [engine.py:136:__init__] RANK=100 STAGE=12 LAYERS=6 [75, 81) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11448073387145996 seconds
Rank: 101 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001287221908569336 seconds
[2023-07-21 23:17:57,012] [INFO] [engine.py:136:__init__] RANK=101 STAGE=12 LAYERS=6 [75, 81) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11374402046203613 seconds
Rank: 102 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0011229515075683594 seconds
[2023-07-21 23:17:57,012] [INFO] [engine.py:136:__init__] RANK=102 STAGE=12 LAYERS=6 [75, 81) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20493292808532715 seconds
Rank: 103 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.001275777816772461 seconds
[2023-07-21 23:17:57,012] [INFO] [engine.py:136:__init__] RANK=103 STAGE=12 LAYERS=6 [75, 81) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.1112220287322998 seconds
Rank: 108 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0013897418975830078 seconds
[2023-07-21 23:17:57,017] [INFO] [engine.py:136:__init__] RANK=108 STAGE=13 LAYERS=6 [81, 87) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.2039639949798584 seconds
Rank: 109 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014667510986328125 seconds
[2023-07-21 23:17:57,017] [INFO] [engine.py:136:__init__] RANK=109 STAGE=13 LAYERS=6 [81, 87) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.20419526100158691 seconds
Rank: 110 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0014014244079589844 seconds
[2023-07-21 23:17:57,017] [INFO] [engine.py:136:__init__] RANK=110 STAGE=13 LAYERS=6 [81, 87) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
Time to load utils op: 0.11116647720336914 seconds
Rank: 111 partition count [1, 1] and sizes[(1358954496, False), (506880, False)] 
Time to load utils op: 0.0015189647674560547 seconds
[2023-07-21 23:17:57,017] [INFO] [engine.py:136:__init__] RANK=111 STAGE=13 LAYERS=6 [81, 87) STAGE_PARAMS=1359461376 (1359.461M) TOTAL_PARAMS=175672197120 (175672.197M) UNIQUE_PARAMS=174841724928 (174841.725M)
[after model, optimizer, and learning rate scheduler are built] datetime: 2023-07-21 23:18:00 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 8
    test:       8
> building train, validation, and test datasets for GPT ...
 > building dataset index ...
    reading sizes...
    reading pointers...
    reading document index...
    creating numpy buffer of mmap...
    creating memory view of numpy buffer...
 > finished creating indexed dataset in 0.028436 seconds
    number of documents: 212001
 > dataset split:
    train:
     document indices in [0, 201189) total of 201189 documents
    validation:
     document indices in [201189, 211789) total of 10600 documents
    test:
     document indices in [211789, 212001) total of 212 documents
 > WARNING: could not find index map files, building the indices on rank 0 ...
 > only one epoch required, setting separate_last_epoch to False
 > elasped time to build and save doc-idx mapping (seconds): 0.007909
    using:
     number of documents:       201189
     number of epochs:          1
     sequence length:           2048
     total number of samples:   127760
 > elasped time to build and save sample-idx mapping (seconds): 0.008001
 > building shuffle index with split [0, 127760) and [127760, 127760) ...
 > elasped time to build and save shuffle-idx mapping (seconds): 0.004507
 > loading doc-idx mapping from /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document_train_indexmap_40ns_2048sl_20548s_doc_idx.npy
 > loading sample-idx mapping from /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document_train_indexmap_40ns_2048sl_20548s_sample_idx.npy
 > loading shuffle-idx mapping from /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document_train_indexmap_40ns_2048sl_20548s_shuffle_idx.npy
    loaded indexed file in 0.009 seconds
    total number of samples: 127761
    total number of epochs: 1
 > WARNING: could not find index map files, building the indices on rank 0 ...
 > only one epoch required, setting separate_last_epoch to False
 > elasped time to build and save doc-idx mapping (seconds): 0.002320
    using:
     number of documents:       10600
     number of epochs:          1
     sequence length:           2048
     total number of samples:   13652
 > elasped time to build and save sample-idx mapping (seconds): 0.001761
 > building shuffle index with split [0, 13652) and [13652, 13652) ...
 > elasped time to build and save shuffle-idx mapping (seconds): 0.002340
 > loading doc-idx mapping from /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document_valid_indexmap_8ns_2048sl_20548s_doc_idx.npy
 > loading sample-idx mapping from /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document_valid_indexmap_8ns_2048sl_20548s_sample_idx.npy
 > loading shuffle-idx mapping from /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document_valid_indexmap_8ns_2048sl_20548s_shuffle_idx.npy
    loaded indexed file in 0.003 seconds
    total number of samples: 13653
    total number of epochs: 1
 > WARNING: could not find index map files, building the indices on rank 0 ...
 > only one epoch required, setting separate_last_epoch to False
 > elasped time to build and save doc-idx mapping (seconds): 0.001596
    using:
     number of documents:       212
     number of epochs:          1
     sequence length:           2048
     total number of samples:   270
 > elasped time to build and save sample-idx mapping (seconds): 0.001517
 > building shuffle index with split [0, 270) and [270, 270) ...
 > elasped time to build and save shuffle-idx mapping (seconds): 0.001919
 > loading doc-idx mapping from /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document_test_indexmap_8ns_2048sl_20548s_doc_idx.npy
 > loading sample-idx mapping from /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document_test_indexmap_8ns_2048sl_20548s_sample_idx.npy
 > loading shuffle-idx mapping from /lus/grand/projects/datascience/vsastry/genslm_subsample_200k_sequence_document/genslm_subsample_200k_sequence_document_test_indexmap_8ns_2048sl_20548s_shuffle_idx.npy
    loaded indexed file in 0.003 seconds
    total number of samples: 271
    total number of epochs: 1
> finished creating GPT datasets ...
[after dataloaders are built] datetime: 2023-07-21 23:18:08 
time (ms) | model-and-optimizer-setup: 17369.33 | train/valid/test-data-iterators-setup: 8325.55
done with setup ...
training ...
[before the start of training step] datetime: 2023-07-21 23:18:08 
[2023-07-21 23:18:08,991] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-07-21 23:18:08,991] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-07-21 23:18:08,992] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with 96 total layers
[2023-07-21 23:18:08,992] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-07-21 23:18:08,995] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
[2023-07-21 23:20:56,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 9.07 | optimizer_gradients: 223.28 | optimizer_step: 438.07
[2023-07-21 23:20:56,251] [INFO] [logging.py:96:log_dist] [Rank 0] step=1, skipped=0, lr=[4.6874999999999995e-08, 4.6874999999999995e-08], mom=[(0.9, 0.999), (0.9, 0.999)]
wandb: WARNING Step cannot be set when using syncing with tensorboard. Please log your step values as a metric such as 'global_step'
[2023-07-21 23:20:56,256] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | batch_input: 289.11 | forward_microstep: 3563.77 | backward_microstep: 13361.26 | backward_inner_microstep: 13361.06 | backward_allreduce_microstep: 0.01 | step_microstep: 931.54
[2023-07-21 23:20:56,258] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 3563.70 | backward: 13361.14 | backward_inner: 13360.96 | backward_allreduce: 0.01 | step: 931.55
[Rank 123] (after 1 iterations) memory (MB) | allocated: 19839.15087890625 | max allocated: 36580.16357421875 | reserved: 38054.0 | max reserved: 38634.0
[Rank 121] (after 1 iterations) memory (MB) | allocated: 19839.15087890625 | max allocated: 36580.16357421875 | reserved: 38054.0 | max reserved: 38346.0
[Rank 3] (after 1 iterations) memory (MB) | allocated: 19579.28662109375 | max allocated: 36320.25244140625 | reserved: 37790.0 | max reserved: 38698.0
[Rank 125] (after 1 iterations) memory (MB) | allocated: 19839.15087890625 | max allocated: 36580.16357421875 | reserved: 38054.0 | max reserved: 38346.0
[Rank 5] (after 1 iterations) memory (MB) | allocated: 19579.28662109375 | max allocated: 36320.25244140625 | reserved: 37790.0 | max reserved: 38554.0
[Rank 11] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
 iteration        1/       5 | consumed samples:            8 | consumed tokens:        16384 | elapsed time per iteration (ms): 169858.7 | learning rate: 4.687E-08 | global batch size:     8 | lm loss: 1.472199E+01 | loss scale: 4096.0 | grad norm: 2474.849 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.047 | TFLOPs: 1.08 |
[Rank 127] (after 1 iterations) memory (MB) | allocated: 19839.15087890625 | max allocated: 36580.16357421875 | reserved: 38054.0 | max reserved: 38634.0
[Rank 19] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 27] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 35] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 1] (after 1 iterations) memory (MB) | allocated: 19579.28662109375 | max allocated: 36320.25244140625 | reserved: 37790.0 | max reserved: 38554.0
[Rank 7] (after 1 iterations) memory (MB) | allocated: 19579.28662109375 | max allocated: 36320.25244140625 | reserved: 37790.0 | max reserved: 38698.0
[Rank 43] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 51] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 59] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 67] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 75] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38646.0
[Rank 83] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38646.0
[Rank 91] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38610.0
[Rank 99] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38466.0
[Rank 107] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38178.0
[Rank 115] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38540.0
[Rank 13] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 21] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 29] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 37] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 45] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 53] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 61] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 69] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 77] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38394.0
[Rank 85] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38358.0
[Rank 93] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38454.0
[Rank 101] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38322.0
[Rank 9] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 109] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38178.0
[Rank 117] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 37890.0
[Rank 17] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 25] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 33] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 41] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 49] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 57] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 65] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 73] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38394.0
[Rank 81] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38358.0
[Rank 89] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38454.0
[Rank 97] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38322.0
[Rank 105] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38178.0
[Rank 113] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 37890.0
[Rank 15] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 23] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 31] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 39] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 47] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 55] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 63] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 71] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 79] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38646.0
[Rank 87] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38646.0
[Rank 95] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38610.0
[Rank 103] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38466.0
[Rank 111] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38178.0
[Rank 119] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38540.0
[Rank 124] (after 1 iterations) memory (MB) | allocated: 19839.15087890625 | max allocated: 36580.16357421875 | reserved: 38054.0 | max reserved: 38490.0
[Rank 4] (after 1 iterations) memory (MB) | allocated: 19579.28662109375 | max allocated: 36320.25244140625 | reserved: 37790.0 | max reserved: 38650.0
[Rank 126] (after 1 iterations) memory (MB) | allocated: 19839.15087890625 | max allocated: 36580.16357421875 | reserved: 38054.0 | max reserved: 38346.0
[Rank 12] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 120] (after 1 iterations) memory (MB) | allocated: 19839.15087890625 | max allocated: 36580.16357421875 | reserved: 38054.0 | max reserved: 38346.0
[Rank 20] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 28] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 36] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 44] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 52] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 6] (after 1 iterations) memory (MB) | allocated: 19579.28662109375 | max allocated: 36320.25244140625 | reserved: 37790.0 | max reserved: 38506.0
[Rank 60] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 68] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38538.0
[Rank 76] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38538.0
[Rank 84] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38502.0
[Rank 92] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38502.0
[Rank 100] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38466.0
[Rank 122] (after 1 iterations) memory (MB) | allocated: 19839.15087890625 | max allocated: 36580.16357421875 | reserved: 38054.0 | max reserved: 38346.0
[Rank 116] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38540.0
[Rank 108] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38178.0
steps: 1 loss: 14.7220 iter time (s): 171.763 samples/sec: 0.047
[2023-07-21 23:21:00,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | pipe_send_output: 29061.80 | pipe_recv_grad: 119945.39
[Rank 0] (after 1 iterations) memory (MB) | allocated: 19627.28662109375 | max allocated: 36368.25244140625 | reserved: 37862.0 | max reserved: 38554.0
[Rank 2] (after 1 iterations) memory (MB) | allocated: 19579.28662109375 | max allocated: 36320.25244140625 | reserved: 37790.0 | max reserved: 38506.0
[Rank 8] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 14] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 22] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 16] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 24] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 32] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 40] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 30] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 48] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 38] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 56] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 46] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 54] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 64] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38430.0
[Rank 62] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 72] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38394.0
[Rank 80] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38358.0
[Rank 70] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 88] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38454.0
[Rank 96] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38466.0
[Rank 104] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38178.0
[Rank 112] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 37890.0
[Rank 78] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38250.0
[Rank 86] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38358.0
[Rank 94] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38358.0
[Rank 102] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38322.0
[Rank 110] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38178.0
[Rank 118] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 37890.0
[Rank 10] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 18] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 26] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 34] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 42] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 50] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 58] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 66] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35056.0 | max reserved: 38286.0
[Rank 74] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38250.0
[Rank 82] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38358.0
[Rank 90] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35052.0 | max reserved: 38358.0
[Rank 98] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38322.0
[Rank 106] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 38178.0
[Rank 114] (after 1 iterations) memory (MB) | allocated: 18166.771484375 | max allocated: 33719.7373046875 | reserved: 35050.0 | max reserved: 37890.0
 iteration        2/       5 | consumed samples:           16 | consumed tokens:        32768 | elapsed time per iteration (ms): 30506.5 | learning rate: 9.375E-08 | global batch size:     8 | lm loss: 1.497511E+01 | loss scale: 4096.0 | grad norm: 2465.500 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.262 | TFLOPs: 6.02 |
[2023-07-21 23:21:29,322] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 9.09 | optimizer_gradients: 222.17 | optimizer_step: 425.49
[2023-07-21 23:21:29,323] [INFO] [logging.py:96:log_dist] [Rank 0] step=2, skipped=0, lr=[9.374999999999999e-08, 9.374999999999999e-08], mom=[(0.9, 0.999), (0.9, 0.999)]
[2023-07-21 23:21:29,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | batch_input: 336.56 | forward_microstep: 2982.43 | backward_microstep: 5370.66 | backward_inner_microstep: 5370.47 | backward_allreduce_microstep: 0.00 | step_microstep: 908.98
[2023-07-21 23:21:29,327] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2982.44 | backward: 5370.56 | backward_inner: 5370.39 | backward_allreduce: 0.00 | step: 908.99
steps: 2 loss: 14.9751 iter time (s): 28.605 samples/sec: 0.280
[2023-07-21 23:21:29,332] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | pipe_send_output: 261.24 | pipe_recv_grad: 18590.72
 iteration        3/       5 | consumed samples:           24 | consumed tokens:        49152 | elapsed time per iteration (ms): 28300.7 | learning rate: 1.406E-07 | global batch size:     8 | lm loss: 1.368637E+01 | loss scale: 4096.0 | grad norm: 2466.634 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.283 | TFLOPs: 6.49 |
[2023-07-21 23:21:57,689] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 9.08 | optimizer_gradients: 253.32 | optimizer_step: 465.69
[2023-07-21 23:21:57,690] [INFO] [logging.py:96:log_dist] [Rank 0] step=3, skipped=0, lr=[1.40625e-07, 1.40625e-07], mom=[(0.9, 0.999), (0.9, 0.999)]
[2023-07-21 23:21:57,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | batch_input: 284.07 | forward_microstep: 3098.33 | backward_microstep: 5454.55 | backward_inner_microstep: 5454.36 | backward_allreduce_microstep: 0.00 | step_microstep: 1036.96
[2023-07-21 23:21:57,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 3098.27 | backward: 5454.45 | backward_inner: 5454.28 | backward_allreduce: 0.00 | step: 1036.97
steps: 3 loss: 13.6864 iter time (s): 28.361 samples/sec: 0.282
[2023-07-21 23:21:57,697] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | pipe_send_output: 328.90 | pipe_recv_grad: 18038.08
 iteration        4/       5 | consumed samples:           32 | consumed tokens:        65536 | elapsed time per iteration (ms): 29003.8 | learning rate: 1.875E-07 | global batch size:     8 | lm loss: 2.034384E+00 | loss scale: 4096.0 | grad norm: 1937.127 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.276 | TFLOPs: 6.33 |
[2023-07-21 23:22:26,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 9.10 | optimizer_gradients: 248.69 | optimizer_step: 429.29
[2023-07-21 23:22:26,617] [INFO] [logging.py:96:log_dist] [Rank 0] step=4, skipped=0, lr=[1.8749999999999998e-07, 1.8749999999999998e-07], mom=[(0.9, 0.999), (0.9, 0.999)]
[2023-07-21 23:22:26,620] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | batch_input: 299.95 | forward_microstep: 3342.46 | backward_microstep: 5249.53 | backward_inner_microstep: 5249.34 | backward_allreduce_microstep: 0.00 | step_microstep: 979.71
[2023-07-21 23:22:26,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 3342.40 | backward: 5249.42 | backward_inner: 5249.25 | backward_allreduce: 0.00 | step: 979.72
steps: 4 loss: 2.0344 iter time (s): 28.927 samples/sec: 0.277
[2023-07-21 23:22:26,628] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | pipe_send_output: 119.75 | pipe_recv_grad: 18799.62
 iteration        5/       5 | consumed samples:           40 | consumed tokens:        81920 | elapsed time per iteration (ms): 28690.7 | learning rate: 2.344E-07 | global batch size:     8 | lm loss: 4.195605E-02 | loss scale: 4096.0 | grad norm: 3.122 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.279 | TFLOPs: 6.40 |
[2023-07-21 23:22:55,327] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 9.09 | optimizer_gradients: 250.42 | optimizer_step: 459.64
[2023-07-21 23:22:55,328] [INFO] [logging.py:96:log_dist] [Rank 0] step=5, skipped=0, lr=[2.3437499999999998e-07, 2.3437499999999998e-07], mom=[(0.9, 0.999), (0.9, 0.999)]
[2023-07-21 23:22:55,331] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | batch_input: 340.56 | forward_microstep: 3661.00 | backward_microstep: 5535.48 | backward_inner_microstep: 5535.29 | backward_allreduce_microstep: 0.00 | step_microstep: 917.66
[2023-07-21 23:22:55,332] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 3660.94 | backward: 5535.38 | backward_inner: 5535.20 | backward_allreduce: 0.00 | step: 917.67
steps: 5 loss: 0.0420 iter time (s): 28.703 samples/sec: 0.279
[2023-07-21 23:22:55,335] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | pipe_send_output: 136.59 | pipe_recv_grad: 17899.64
[after training is done] datetime: 2023-07-21 23:22:55 
------------------------------------------------------------------------------------------------------------------
 validation loss at the end of training for val data | lm loss value: 2.600896E-02 | lm loss PPL: 1.026350E+00 | 
------------------------------------------------------------------------------------------------------------------
Evaluating iter 1/1
-------------------------------------------------------------------------------------------------------------------
 validation loss at the end of training for test data | lm loss value: 2.581674E-02 | lm loss PPL: 1.026153E+00 | 
-------------------------------------------------------------------------------------------------------------------
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:              Train/Samples/eval_loss █▁
wandb:             Train/Samples/loss_scale ▁▁▁▁▁
wandb:                     Train/Samples/lr ▁▃▅▆█
wandb:             Train/Samples/train_loss ██▇▂▁
wandb:                        pretrain_time ▁
wandb: throughput/approx_params_in_billions ▁▁▁▁▁
wandb:            throughput/iteration-time █▁▁▁▁
wandb:           throughput/samples_per_sec ▁████
wandb:                    throughput/tflops ▁████
wandb: 
wandb: Run summary:
wandb:              Train/Samples/eval_loss 0.02582
wandb:             Train/Samples/loss_scale 4096
wandb:                     Train/Samples/lr 0.0
wandb:             Train/Samples/train_loss 0.04196
wandb:                        pretrain_time 355.11857
wandb: throughput/approx_params_in_billions 187.29861
wandb:            throughput/iteration-time 28.70709
wandb:           throughput/samples_per_sec 0.27868
wandb:                    throughput/tflops 6.39396
wandb: 
wandb: 🚀 View run dandy-snow-10 at: https://wandb.ai/alcf-test/Megatron-LM/runs/2cpu87xm
wandb: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./outputs/GPT3_actCkpt_flashAttn_175B_z1_seqlen2048_mp8_pp16_nl96_hs12288_gb8_mb1_gas8/tensorboard/wandb/run-20230721_231654-2cpu87xm/logs
Comm. Op            Message Size        Count               Total Latency(ms)   Avg Latency(ms)     tput_avg (Gbps)     busbw_avg (Gbps)    
